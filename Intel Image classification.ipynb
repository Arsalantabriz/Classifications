{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import random_split\nimport torchvision\nimport matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import datasets, models, transforms\nimport os","metadata":{"execution":{"iopub.status.busy":"2023-09-23T16:02:18.391054Z","iopub.execute_input":"2023-09-23T16:02:18.391531Z","iopub.status.idle":"2023-09-23T16:02:18.399085Z","shell.execute_reply.started":"2023-09-23T16:02:18.391496Z","shell.execute_reply":"2023-09-23T16:02:18.398043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([transforms.Resize((32,32)),transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])","metadata":{"execution":{"iopub.status.busy":"2023-09-23T16:02:22.808535Z","iopub.execute_input":"2023-09-23T16:02:22.809098Z","iopub.status.idle":"2023-09-23T16:02:22.817874Z","shell.execute_reply.started":"2023-09-23T16:02:22.809054Z","shell.execute_reply":"2023-09-23T16:02:22.816178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-09-23T16:02:25.097637Z","iopub.execute_input":"2023-09-23T16:02:25.098079Z","iopub.status.idle":"2023-09-23T16:02:25.104150Z","shell.execute_reply.started":"2023-09-23T16:02:25.098045Z","shell.execute_reply":"2023-09-23T16:02:25.102937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_dir = '/kaggle/input/intel-image-classification/seg_train/seg_train'\ntest_data_dir = '/kaggle/input/intel-image-classification/seg_test/seg_test'\npred_data_dir = '/kaggle/input/intel-image-classification/seg_pred/seg_pred'","metadata":{"execution":{"iopub.status.busy":"2023-09-23T16:03:54.714840Z","iopub.execute_input":"2023-09-23T16:03:54.715341Z","iopub.status.idle":"2023-09-23T16:03:54.723443Z","shell.execute_reply.started":"2023-09-23T16:03:54.715307Z","shell.execute_reply":"2023-09-23T16:03:54.721906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datasets = datasets.ImageFolder(os.path.join(train_data_dir),\n                                      transform=transform)\ntest_datasets = datasets.ImageFolder(os.path.join(test_data_dir),\n                                    transform=transform)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T16:04:15.521271Z","iopub.execute_input":"2023-09-23T16:04:15.521813Z","iopub.status.idle":"2023-09-23T16:04:18.685256Z","shell.execute_reply.started":"2023-09-23T16:04:15.521777Z","shell.execute_reply":"2023-09-23T16:04:18.684027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_size = len(train_datasets)\ntrain_size = int(0.7 * total_size)\nval_size = total_size - train_size\n\ntrain_set, val_set = random_split(train_datasets, [train_size, val_size])","metadata":{"execution":{"iopub.status.busy":"2023-09-23T16:05:55.435076Z","iopub.execute_input":"2023-09-23T16:05:55.435608Z","iopub.status.idle":"2023-09-23T16:05:55.470727Z","shell.execute_reply.started":"2023-09-23T16:05:55.435569Z","shell.execute_reply":"2023-09-23T16:05:55.469632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating data loaders\n\nfrom torch.utils.data import DataLoader\n\nbatch_size = 40\n\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=batch_size)\ntest_loader = DataLoader(test_datasets, batch_size=batch_size)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T16:06:13.069286Z","iopub.execute_input":"2023-09-23T16:06:13.069791Z","iopub.status.idle":"2023-09-23T16:06:13.077702Z","shell.execute_reply.started":"2023-09-23T16:06:13.069748Z","shell.execute_reply":"2023-09-23T16:06:13.076371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define Classes\n\nclasses=(\"buildings\",\"forest\",\"glacier\",\"mountain\",\"sea\",\"street\")","metadata":{"execution":{"iopub.status.busy":"2023-09-23T16:06:15.919625Z","iopub.execute_input":"2023-09-23T16:06:15.920177Z","iopub.status.idle":"2023-09-23T16:06:15.927894Z","shell.execute_reply.started":"2023-09-23T16:06:15.920129Z","shell.execute_reply":"2023-09-23T16:06:15.926256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# unnormalize\n\ndef imshow(imgs):\n    imgs = imgs / 2 + 0.5   # unnormalize\n    npimgs = imgs.numpy()\n    plt.imshow(np.transpose(npimgs, (1, 2, 0)))\n    plt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-23T16:06:18.032061Z","iopub.execute_input":"2023-09-23T16:06:18.032499Z","iopub.status.idle":"2023-09-23T16:06:18.040199Z","shell.execute_reply.started":"2023-09-23T16:06:18.032464Z","shell.execute_reply":"2023-09-23T16:06:18.038656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Iterate, loading images, make_grid\n\ndataiter=iter(train_loader)\nimages,labels=next(dataiter)\nimg_grid = torchvision.utils.make_grid(images[0:25], nrow=5)\nimshow(img_grid)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T16:06:19.852521Z","iopub.execute_input":"2023-09-23T16:06:19.852990Z","iopub.status.idle":"2023-09-23T16:06:20.696579Z","shell.execute_reply.started":"2023-09-23T16:06:19.852957Z","shell.execute_reply":"2023-09-23T16:06:20.695628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomCNN(nn.Module):\n    def __init__(self):\n        super(CustomCNN, self).__init__()\n        \n        # Convolutional Layers\n        self.conv1 = nn.Conv2d(3,32,3)\n        self.pool=nn.MaxPool2d(2,2)\n        self.conv2=nn.Conv2d(32,64,3)\n        self.conv3=nn.Conv2d(64,64,3)\n        self.fc1=nn.Linear(64*4*4,64)\n        self.fc2=nn.Linear(64,6)\n        \n    def forward(self,x):\n        x=F.relu(self.conv1(x))\n        x=self.pool(x)\n        x=F.relu(self.conv2(x))\n        x=self.pool(x)\n        x=F.relu(self.conv3(x))\n        x=torch.flatten(x,1)\n        x=F.relu(self.fc1(x))\n        x=self.fc2(x)\n        \n        return x\n    \n\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T16:06:23.956018Z","iopub.execute_input":"2023-09-23T16:06:23.956561Z","iopub.status.idle":"2023-09-23T16:06:23.969397Z","shell.execute_reply.started":"2023-09-23T16:06:23.956522Z","shell.execute_reply":"2023-09-23T16:06:23.967159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=CustomCNN().to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T16:06:28.556876Z","iopub.execute_input":"2023-09-23T16:06:28.557346Z","iopub.status.idle":"2023-09-23T16:06:28.568802Z","shell.execute_reply.started":"2023-09-23T16:06:28.557311Z","shell.execute_reply":"2023-09-23T16:06:28.567837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 10\nbatch_size = 32\nlearning_rate = 0.001\n\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T16:06:31.991865Z","iopub.execute_input":"2023-09-23T16:06:31.992386Z","iopub.status.idle":"2023-09-23T16:06:32.000245Z","shell.execute_reply.started":"2023-09-23T16:06:31.992335Z","shell.execute_reply":"2023-09-23T16:06:31.998602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_total_steps = len(train_loader)\nfor epoch in range(num_epochs):\n\n    running_loss = 0.0\n\n    for i, (images, labels) in enumerate(train_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n\n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        # Backward and optimize\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        running_loss += loss.item()\n\n    print(f'[{epoch + 1}] loss: {running_loss / n_total_steps:.3f}')\n\nprint('Finished Training')\nPATH = './cnn.pth'\ntorch.save(model.state_dict(), PATH)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T16:06:34.401677Z","iopub.execute_input":"2023-09-23T16:06:34.402091Z","iopub.status.idle":"2023-09-23T16:11:25.229128Z","shell.execute_reply.started":"2023-09-23T16:06:34.402059Z","shell.execute_reply":"2023-09-23T16:11:25.228087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaded_model = CustomCNN()\nloaded_model.load_state_dict(torch.load(PATH)) # it takes the loaded dictionary, not the path file itself\nloaded_model.to(device)\nloaded_model.eval()\n\nwith torch.no_grad():\n    n_correct = 0\n    n_correct2 = 0\n    n_samples = len(test_loader.dataset)\n\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n\n        # max returns (value ,index)\n        _, predicted = torch.max(outputs, 1)\n        n_correct += (predicted == labels).sum().item()\n\n        outputs2 = loaded_model(images)\n        _, predicted2 = torch.max(outputs2, 1)\n        n_correct2 += (predicted2 == labels).sum().item()\n\n    acc = 100.0 * n_correct / n_samples\n    print(f'Accuracy of the model: {acc} %')\n\n    acc = 100.0 * n_correct2 / n_samples\n    print(f'Accuracy of the loaded model: {acc} %')","metadata":{"execution":{"iopub.status.busy":"2023-09-23T16:11:30.008089Z","iopub.execute_input":"2023-09-23T16:11:30.008734Z","iopub.status.idle":"2023-09-23T16:11:53.842138Z","shell.execute_reply.started":"2023-09-23T16:11:30.008682Z","shell.execute_reply":"2023-09-23T16:11:53.840702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\n\n# Initialize variables to keep track of correct predictions and total samples\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\naccuracy = 100 * correct / total\nprint(f'validation Accuracy: {accuracy:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2023-09-23T16:11:53.845041Z","iopub.execute_input":"2023-09-23T16:11:53.845522Z","iopub.status.idle":"2023-09-23T16:12:25.412824Z","shell.execute_reply.started":"2023-09-23T16:11:53.845481Z","shell.execute_reply":"2023-09-23T16:12:25.411933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}